{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl\n",
    "\n",
    "from utils.aug import load\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from arch import IOGCN, IOGAT, IOMLP, GCN, GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, feat, labels, num_class, train_idx, val_idx, test_idx = load(\"cora\")\n",
    "in_dim = feat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 0\n",
    "lambd = 1e-3\n",
    "n_epochs = 500\n",
    "\n",
    "n_layers = 1\n",
    "hid_dim = 16\n",
    "out_dim = num_class\n",
    "nonlin = nn.ReLU\n",
    "\n",
    "eval_freq = 20\n",
    "es_patience = 200\n",
    "subgraph = \"neigh_sampling\" # random, neigh_sampling\n",
    "method = \"transpose\" # linear, fill\n",
    "N = graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_params_gcn = {'norm': 'both', 'bias': False}\n",
    "build_params_gat = {'num_heads': 8, 'feat_drop': 0.2, 'attn_drop': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neigh_sampling(A, K=6):\n",
    "    N = A.shape[0]\n",
    "    init_node_X = np.random.randint(N)\n",
    "    init_node_Y = np.random.randint(N)\n",
    "\n",
    "    list_nodes_x = [init_node_X]\n",
    "    list_nodes_y = [init_node_Y]\n",
    "\n",
    "    for k in range(K):\n",
    "        new_nodes_x = list_nodes_x.copy()\n",
    "        new_nodes_y = list_nodes_y.copy()\n",
    "        for x in list_nodes_x:\n",
    "            new_nodes_x.extend(np.where(A[x,:] == 1)[0])\n",
    "        for y in list_nodes_y:\n",
    "            new_nodes_y.extend(np.where(A[y,:] == 1)[0])\n",
    "        \n",
    "        # Remove duplicates\n",
    "        list_nodes_x = list(set(new_nodes_x))\n",
    "        list_nodes_y = list(set(new_nodes_y))\n",
    "    return list_nodes_x, list_nodes_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subgraph == \"random\":\n",
    "    Nx = Ny = 512\n",
    "    idxs_X = torch.randperm(N)[:Nx]\n",
    "    idxs_Y = torch.randperm(N)[:Ny]\n",
    "elif subgraph == \"neigh_sampling\":\n",
    "    Nx = Ny = 0\n",
    "    while Nx < 10 or Ny < 10:\n",
    "        idxs_X, idxs_Y = neigh_sampling(graph.cpu().adj().to_dense(), K=2)\n",
    "        Nx = len(idxs_X)\n",
    "        Ny = len(idxs_Y)\n",
    "        print(f\"{Nx=}, {Ny=} - \", end=\"\")\n",
    "    common_nodes = [x for x in idxs_X if x in idxs_Y]\n",
    "    idxs_common_x = [idxs_X.index(x) for x in common_nodes]\n",
    "    idxs_common_y = [idxs_Y.index(x) for x in common_nodes]\n",
    "    idxs_common = (idxs_common_x,idxs_common_y)\n",
    "\n",
    "gx = graph.subgraph(idxs_X).add_self_loop()\n",
    "gy = graph.subgraph(idxs_Y).add_self_loop()\n",
    "#graph = graph.add_self_loop()\n",
    "#Nin = gx.number_of_nodes()\n",
    "x = feat[idxs_X,:]\n",
    "\n",
    "gx = gx.to(device)\n",
    "gy = gy.to(device)\n",
    "graph = graph.to(device)\n",
    "x = x.to(device)\n",
    "labels_y = labels[idxs_Y].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_y_split = torch.randperm(Ny)\n",
    "N_train = 0.3\n",
    "N_val = 0.2\n",
    "train_idx = idxs_y_split[:int(N_train*Ny)]\n",
    "val_idx = []\n",
    "test_idx = idxs_y_split[int(N_train*Ny):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"fill\" or method == \"linear\": # Defaulting here in case of linear transformation\n",
    "    x_gcn = torch.ones((N, x.shape[1]), device=device)\n",
    "    #x_gcn[idxs] = x\n",
    "elif method == \"graph\":\n",
    "    adj = graph.adjacency_matrix().to_dense().to(device)\n",
    "    x_gcn = adj[:,idxs_X] @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x, y, gx, gy, graph, lr, train_idx, val_idx, test_idx, model_name=\"io\", es_patience=-1, verbose=True):\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses, acc_train, acc_val, acc_test = [np.zeros(n_epochs) for _ in range(4)]\n",
    "\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    es_count = 0\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        if model_name == \"io\":\n",
    "            yhat = model(gx, gy, x)\n",
    "        else:\n",
    "            yhat = model(graph, x)\n",
    "        loss = loss_fn(yhat[train_idx], y[train_idx])\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        preds = torch.argmax(yhat, 1)\n",
    "        results = (preds == y).type(torch.float32)\n",
    "        acc_train[i] = results[train_idx].mean().item()\n",
    "        acc_val[i] = results[val_idx].mean().item()\n",
    "        acc_test[i] = results[test_idx].mean().item()\n",
    "\n",
    "        if acc_val[i] > best_val_acc:\n",
    "            es_count = 0\n",
    "            best_val_acc = acc_val[i]\n",
    "            best_test_acc = acc_test[i]\n",
    "        else:\n",
    "            es_count += 1\n",
    "\n",
    "        if es_patience > 0 and es_count > es_patience:\n",
    "            break\n",
    "\n",
    "        losses[i] = loss.item()\n",
    "\n",
    "        if (i == 0 or (i+1) % eval_freq == 0) and verbose:\n",
    "            print(f\"Epoch {i+1}/{n_epochs} - Loss: {losses[i]} - Train Acc: {acc_train[i]} - Test Acc: {acc_test[i]}\", flush=True)\n",
    "\n",
    "    return losses, acc_train, acc_val, acc_test, best_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iogcn = IOGCN(in_dim, hid_dim, out_dim, Nx, Ny, n_layers, [], method, build_params_gcn, nonlin=nonlin).to(device)\n",
    "_, acc_train_iogcn, acc_val_iogcn, acc_test_iogcn, _ = test(iogcn, x, labels_y, gx, gy, graph, lr, train_idx, val_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iomlp = IOMLP(in_dim, hid_dim, out_dim, Nx, Ny, n_layers, [], method, build_params_gcn, nonlin=nonlin).to(device)\n",
    "_, acc_train_iomlp, acc_val_iomlp, acc_test_iomlp, _ = test(iomlp, x, labels_y, gx, gy, graph, lr, train_idx, val_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iogat = IOGAT(in_dim, hid_dim, out_dim, Nx, Ny, n_layers, [], method, build_params_gat, nonlin=nonlin).to(device)\n",
    "_, acc_train_iogat, acc_val_iogat, acc_test_iogat, _ = test(iogat, x, labels_y, gx, gy, graph, lr, train_idx, val_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogcn)\n",
    "plt.plot(np.arange(n_epochs), acc_test_iomlp)\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogat)\n",
    "#plt.plot(np.arange(n_epochs), acc_test_only_gcn)\n",
    "\n",
    "plt.legend([\"IOGCN\", \"IOMLP\", \"IOGAT\"], fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_orig_reorder = np.array(idxs_Y)[idxs_y_split.numpy()]\n",
    "train_idx_orig = torch.from_numpy(idxs_orig_reorder[:int(N_train*Ny)])\n",
    "val_idx_orig = torch.from_numpy(idxs_orig_reorder[int(N_train*Ny):int((N_train+N_val)*Ny)])\n",
    "test_idx_orig = torch.from_numpy(idxs_orig_reorder[int((N_train+N_val)*Ny):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_to_remove = []\n",
    "start_edges = graph.edges()[0].tolist()\n",
    "end_edges = graph.edges()[1].tolist()\n",
    "\n",
    "for i in range(graph.number_of_edges()):\n",
    "    if not (start_edges[i] in idxs_Y and end_edges[i] in idxs_Y):\n",
    "        edges_to_remove.append(i)\n",
    "\n",
    "graph_pruned = graph.clone()\n",
    "graph_pruned.remove_edges(edges_to_remove)\n",
    "assert graph_pruned.number_of_edges() == gy.number_of_edges() - gy.number_of_nodes() # - because self loop\n",
    "\n",
    "graph_pruned = graph_pruned.add_self_loop().to(device)\n",
    "\n",
    "x_pruned = torch.zeros(feat.shape)\n",
    "x_pruned[idxs_X,:] = feat[idxs_X,:]\n",
    "\n",
    "gcn = GCN(in_dim, hid_dim, out_dim, 2*n_layers, nonlin, build_params_gcn).to(device)\n",
    "loss_gcn_limited, acc_train_gcn_limited, acc_val_gcn_limited, acc_test_gcn_limited, best_acc_test_gcn_limited = test(gcn, x_pruned.to(device), labels.to(device), gx, gy, graph_pruned, 1e-2, train_idx_orig, val_idx_orig, test_idx_orig, model_name=\"gcn\", es_patience=es_patience, verbose=False)\n",
    "\n",
    "best_acc_test_gcn_limited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exhaustive tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SIMS = 10\n",
    "methods = [\"linear\", \"transpose\", \"common\"]\n",
    "accs_test_iogcn, accs_test_iomlp, accs_test_iogat, losses_iogcn, losses_iomlp, losses_iogat = [np.zeros((N_SIMS, len(methods), n_epochs)) for _ in range(6)]\n",
    "accs_test_gcn = np.zeros((N_SIMS, n_epochs))\n",
    "losses_gcn = np.zeros((N_SIMS, n_epochs))\n",
    "accs_test_gat = np.zeros((N_SIMS, n_epochs))\n",
    "losses_gat = np.zeros((N_SIMS, n_epochs))\n",
    "\n",
    "for sim in range(N_SIMS):\n",
    "    print(f\"Simulation {sim+1} \", end=\"\")\n",
    "    if subgraph == \"random\":\n",
    "        Nx = Ny = 512\n",
    "        idxs_X = torch.randperm(N)[:Nx].to(device)\n",
    "        idxs_Y = torch.randperm(N)[:Ny].to(device)\n",
    "    elif subgraph == \"neigh_sampling\":\n",
    "        Nx = Ny = 0\n",
    "        while Nx < 10 or Ny < 10:\n",
    "            idxs_X, idxs_Y = neigh_sampling(graph.cpu().adj().to_dense(), K=2)\n",
    "            Nx = len(idxs_X)\n",
    "            Ny = len(idxs_Y)\n",
    "            print(f\"{Nx=}, {Ny=} - \", end=\"\")\n",
    "        common_nodes = [x for x in idxs_X if x in idxs_Y]\n",
    "        idxs_common_x = [idxs_X.index(x) for x in common_nodes]\n",
    "        idxs_common_y = [idxs_Y.index(x) for x in common_nodes]\n",
    "        idxs_common = (idxs_common_x,idxs_common_y)\n",
    "\n",
    "    gx = graph.subgraph(idxs_X).add_self_loop()\n",
    "    gy = graph.subgraph(idxs_Y).add_self_loop()\n",
    "    x = feat[idxs_X,:]\n",
    "\n",
    "    gx = gx.to(device)\n",
    "    gy = gy.to(device)\n",
    "    graph = graph.to(device)\n",
    "    x = x.to(device)\n",
    "    labels_y = labels[idxs_Y].to(device)\n",
    "\n",
    "    Sx = gx.clone().adj().to_dense().to(\"cuda\")\n",
    "    Sy = gy.clone().adj().to_dense().to(\"cuda\")\n",
    "\n",
    "    idxs_y_split = torch.randperm(Ny)\n",
    "    N_train = 0.3\n",
    "    N_val = 0.2\n",
    "    train_idx = idxs_y_split[:int(N_train*Ny)]\n",
    "    val_idx = idxs_y_split[int(N_train*Ny):int((N_train+N_val)*Ny)]\n",
    "    test_idx = idxs_y_split[int(N_train*Ny):]\n",
    "\n",
    "    idxs_orig_reorder = np.array(idxs_Y)[idxs_y_split.numpy()]\n",
    "    train_idx_orig = torch.from_numpy(idxs_orig_reorder[:int(N_train*Ny)])\n",
    "    val_idx_orig = torch.from_numpy(idxs_orig_reorder[int(N_train*Ny):int((N_train+N_val)*Ny)])\n",
    "    test_idx_orig = torch.from_numpy(idxs_orig_reorder[int((N_train+N_val)*Ny):])\n",
    "\n",
    "    for j, m in enumerate(methods):\n",
    "\n",
    "        iogcn = IOGCN(in_dim, hid_dim, out_dim, Nx, Ny, n_layers, idxs_common, m, build_params_gcn, nonlin=nonlin).to(device)\n",
    "        iogat = IOGAT(in_dim, hid_dim, out_dim, Nx, Ny, n_layers, idxs_common, m, build_params_gat, nonlin=nonlin).to(device)\n",
    "        iomlp = IOMLP(in_dim, hid_dim, out_dim, Nx, Ny, n_layers, idxs_common, m, build_params_gcn, nonlin=nonlin).to(device)\n",
    "\n",
    "        loss_iogcn, acc_train_iogcn, acc_val_iogcn, acc_test_iogcn, _ = test(iogcn, x, labels_y, gx, gy, graph, lr, train_idx, val_idx, test_idx, verbose=False)\n",
    "        loss_iogat, acc_train_iogat, acc_val_iogat, acc_test_iogat, _ = test(iogat, x, labels_y, gx, gy, graph, lr, train_idx, val_idx, test_idx, verbose=False)\n",
    "        loss_iomlp, acc_train_iomlp, acc_val_iomlp, acc_test_iomlp, _ = test(iomlp, x, labels_y, gx, gy, graph, lr, train_idx, val_idx, test_idx, verbose=False)\n",
    "\n",
    "        print(f\"{acc_test_iogcn[-1]=:.6f}, {acc_test_iogat[-1]=:.6f}, {loss_iogcn[-1]=:.6f}, {loss_iogat[-1]=:.6f}\")\n",
    "\n",
    "        accs_test_iogcn[sim,j,:] = acc_test_iogcn\n",
    "        accs_test_iogat[sim,j,:] = acc_test_iogat\n",
    "        accs_test_iomlp[sim,j,:] = acc_test_iomlp\n",
    "        losses_iogcn[sim,j,:] = loss_iogcn\n",
    "        losses_iogat[sim,j,:] = loss_iogat\n",
    "        losses_iomlp[sim,j,:] = loss_iomlp\n",
    "\n",
    "    lr_gcn = 1e-2\n",
    "    gcn = GCN(in_dim, hid_dim, out_dim, 2*n_layers, nonlin, build_params_gcn).to(device)\n",
    "    loss_gcn, acc_train_gcn, acc_val_gcn, acc_test_gcn, _ = test(gcn, feat.to(device), labels.to(device), gx, gy, graph.clone().add_self_loop(), lr_gcn, train_idx_orig, val_idx_orig, test_idx_orig, model_name=\"gcn\", verbose=False)\n",
    "\n",
    "    gat = GAT(in_dim, hid_dim, out_dim, 2*n_layers, nonlin, build_params_gat).to(device)\n",
    "    loss_gat, acc_train_gat, acc_val_gat, acc_test_gat, _ = test(gat, feat.to(device), labels.to(device), gx, gy, graph.clone().add_self_loop(), lr_gcn, train_idx_orig, val_idx_orig, test_idx_orig, model_name=\"gat\", verbose=False)\n",
    "\n",
    "    accs_test_gcn[sim,:] = acc_test_gcn\n",
    "    losses_gcn[sim,:] = loss_gcn\n",
    "    accs_test_gat[sim,:] = acc_test_gat\n",
    "    losses_gat[sim,:] = loss_gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,8))\n",
    "\n",
    "acc_test_iogcn, acc_test_iogat, acc_test_iomlp, acc_test_gcn, acc_test_gat, loss_iogcn, loss_iogat, loss_iomlp, loss_gcn, loss_gat = \\\n",
    "    [100*np.mean(elem, 0) for elem in [accs_test_iogcn, accs_test_iogat, accs_test_iomlp, accs_test_gcn, accs_test_gat, losses_iogcn, losses_iogat, losses_iomlp, losses_gcn, losses_gat]]\n",
    "\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogcn[0,:], label=\"IOGCN-W\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogat[0,:], label=\"IOGAT-W\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iomlp[0,:], label=\"IOMLP-W\")\n",
    "\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogcn[1,:], label=\"IOGCN-T\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogat[1,:], label=\"IOGAT-T\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iomlp[1,:], label=\"IOMLP-T\")\n",
    "\n",
    "plt.plot(np.arange(n_epochs), acc_test_gcn, label=\"GCN\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_gat, label=\"GAT\")\n",
    "\n",
    "\n",
    "f.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogcn[0,:], label=\"IOGCN-W\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogat[0,:], label=\"IOGAT-W\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iomlp[0,:], label=\"IOMLP-W\")\n",
    "\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogcn[1,:], label=\"IOGCN-T\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogat[1,:], label=\"IOGAT-T\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iomlp[1,:], label=\"IOMLP-T\")\n",
    "\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogcn[2,:], label=\"IOGCN-C\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iogat[2,:], label=\"IOGAT-C\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_iomlp[2,:], label=\"IOMLP-C\")\n",
    "\n",
    "plt.plot(np.arange(n_epochs), acc_test_gcn, label=\"GCN\")\n",
    "plt.plot(np.arange(n_epochs), acc_test_gat, color='c', label=\"GAT\")\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.title(\"Evolution of the accuracy measured on the test node set\", fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SIMS = 25\n",
    "methods = [\"linear\", \"transpose\", \"common\"]\n",
    "Ks = [2,3,4,5,6,7,8]\n",
    "subgraph = \"neigh_sampling\"\n",
    "\n",
    "accs_test_iogcn, accs_test_ogcn, accs_test_iomlp, accs_test_iogat,\\\n",
    "    losses_iogcn, losses_ogcn, losses_iomlp, losses_iogat =\\\n",
    "    [np.zeros((len(Ks), N_SIMS, len(methods),n_epochs)) for _ in range(8)]\n",
    "\n",
    "best_accs_test_iogcn, best_accs_test_ogcn, best_accs_test_iomlp, best_accs_test_iogat = \\\n",
    "    [np.zeros((len(Ks), N_SIMS, len(methods))) for _ in range(4)]\n",
    "\n",
    "accs_test_gcn = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "best_accs_test_gcn = np.zeros((len(Ks), N_SIMS))\n",
    "losses_gcn = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "accs_test_gcn_limited_x = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "best_accs_test_gcn_limited_x = np.zeros((len(Ks), N_SIMS))\n",
    "losses_gcn_limited_x = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "accs_test_gcn_limited_y = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "best_accs_test_gcn_limited_y = np.zeros((len(Ks), N_SIMS))\n",
    "losses_gcn_limited_y = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "accs_test_gcn_limited_xy = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "best_accs_test_gcn_limited_xy = np.zeros((len(Ks), N_SIMS))\n",
    "losses_gcn_limited_xy = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "accs_test_gat = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "best_accs_test_gat = np.zeros((len(Ks), N_SIMS))\n",
    "losses_gat = np.zeros((len(Ks), N_SIMS,n_epochs))\n",
    "\n",
    "for k, n_neigh in enumerate(Ks):\n",
    "    print(f\"****** Starting {n_neigh} neighbors ****** (simulation out of {N_SIMS}): \", end=\"\")\n",
    "\n",
    "    for sim in range(N_SIMS):\n",
    "\n",
    "        print(f\"{sim+1} \", end=\"\", flush=True)\n",
    "\n",
    "        if subgraph == \"random\":\n",
    "            Nx = Ny = 512\n",
    "            idxs_X = torch.randperm(N)[:Nx].to(device)\n",
    "            idxs_Y = torch.randperm(N)[:Ny].to(device)\n",
    "        elif subgraph == \"neigh_sampling\":\n",
    "            Nx = Ny = 0\n",
    "            while Nx < 10 or Ny < 10: # Ensure at least 10 nodes in each graph\n",
    "                idxs_X, idxs_Y = neigh_sampling(graph.cpu().adj().to_dense(), K=n_neigh)\n",
    "                Nx = len(idxs_X)\n",
    "                Ny = len(idxs_Y)\n",
    "                #print(f\"{Nx=}, {Ny=} - \", end=\"\")\n",
    "            common_nodes = [x for x in idxs_X if x in idxs_Y]\n",
    "            idxs_common_x = [idxs_X.index(x) for x in common_nodes]\n",
    "            idxs_common_y = [idxs_Y.index(x) for x in common_nodes]\n",
    "            idxs_common = (idxs_common_x,idxs_common_y)\n",
    "\n",
    "        gx = graph.subgraph(idxs_X).add_self_loop()\n",
    "        gy = graph.subgraph(idxs_Y).add_self_loop()\n",
    "        x = feat[idxs_X,:]\n",
    "\n",
    "        gx = gx.to(device)\n",
    "        gy = gy.to(device)\n",
    "        graph = graph.to(device)\n",
    "        x = x.to(device)\n",
    "        labels_y = labels[idxs_Y].to(device)\n",
    "\n",
    "        idxs_y_split = torch.randperm(Ny)\n",
    "        N_train = 0.3\n",
    "        N_val = 0.2\n",
    "        train_idx = idxs_y_split[:int(N_train*Ny)]\n",
    "        val_idx = idxs_y_split[int(N_train*Ny):int((N_train+N_val)*Ny)]\n",
    "        test_idx = idxs_y_split[int((N_train+N_val)*Ny):]\n",
    "\n",
    "        idxs_orig_reorder = np.array(idxs_Y)[idxs_y_split.numpy()]\n",
    "        train_idx_orig = torch.from_numpy(idxs_orig_reorder[:int(N_train*Ny)])\n",
    "        val_idx_orig = torch.from_numpy(idxs_orig_reorder[int(N_train*Ny):int((N_train+N_val)*Ny)])\n",
    "        test_idx_orig = torch.from_numpy(idxs_orig_reorder[int((N_train+N_val)*Ny):])\n",
    "\n",
    "        for j, m in enumerate(methods):\n",
    "\n",
    "            iogcn = IOGCN(in_dim, hid_dim, out_dim, Nx, Ny, n_layers, idxs_common, m, build_params_gcn, nonlin=nonlin).to(device)\n",
    "            iogat = IOGAT(in_dim, hid_dim, out_dim, Nx, Ny, n_layers, idxs_common, m, build_params_gat, nonlin=nonlin).to(device)\n",
    "            iomlp = IOMLP(in_dim, hid_dim, out_dim, Nx, Ny, n_layers, idxs_common, m, build_params_gcn, nonlin=nonlin).to(device)\n",
    "\n",
    "            loss_iogcn, acc_train_iogcn, acc_val_iogcn, acc_test_iogcn, best_acc_test_iogcn = test(iogcn, x, labels_y, gx, gy, graph, lr, train_idx, val_idx, test_idx, es_patience=es_patience, verbose=False)\n",
    "            loss_iogat, acc_train_iogat, acc_val_iogat, acc_test_iogat, best_acc_test_iogat = test(iogat, x, labels_y, gx, gy, graph, lr, train_idx, val_idx, test_idx, es_patience=es_patience, verbose=False)\n",
    "            loss_iomlp, acc_train_iomlp, acc_val_iomlp, acc_test_iomlp, best_acc_test_iomlp = test(iomlp, x, labels_y, gx, gy, graph, lr, train_idx, val_idx, test_idx, es_patience=es_patience, verbose=False)\n",
    "\n",
    "            #print(f\"{acc_test_iogcn[-1]=:.6f}, {acc_test_iogat[-1]=:.6f}, {acc_test_ogcn[-1]=:.6f}, {loss_iogcn[-1]=:.6f}, {loss_ogcn[-1]=:.6f}\")\n",
    "\n",
    "            accs_test_iogcn[k,sim,j,:] = acc_test_iogcn\n",
    "            accs_test_iogat[k,sim,j,:] = acc_test_iogat\n",
    "            accs_test_iomlp[k,sim,j,:] = acc_test_iomlp\n",
    "            best_accs_test_iogcn[k,sim,j] = best_acc_test_iogcn\n",
    "            best_accs_test_iogat[k,sim,j] = best_acc_test_iogat\n",
    "            best_accs_test_iomlp[k,sim,j] = best_acc_test_iomlp\n",
    "            losses_iogcn[k,sim,j,:] = loss_iogcn\n",
    "            losses_iogat[k,sim,j,:] = loss_iogat\n",
    "            losses_iomlp[k,sim,j,:] = loss_iomlp\n",
    "\n",
    "        lr_gcn = 1e-2\n",
    "        gcn = GCN(in_dim, hid_dim, out_dim, 2*n_layers, nonlin, build_params_gcn).to(device)\n",
    "        loss_gcn, acc_train_gcn, acc_val_gcn, acc_test_gcn, best_acc_test_gcn = test(gcn, feat.to(device), labels.to(device), gx, gy, graph.clone().add_self_loop(), lr_gcn, train_idx_orig, val_idx_orig, test_idx_orig, model_name=\"gcn\", es_patience=es_patience, verbose=False)\n",
    "\n",
    "        edges_to_remove_x = []\n",
    "        edges_to_remove_y = []\n",
    "        edges_to_remove_xy = []\n",
    "        start_edges = graph.edges()[0].tolist()\n",
    "        end_edges = graph.edges()[1].tolist()\n",
    "\n",
    "        idxs_XY = list(set(idxs_X + idxs_Y))\n",
    "\n",
    "        for i in range(graph.number_of_edges()):\n",
    "            if not (start_edges[i] in idxs_X and end_edges[i] in idxs_X):\n",
    "                edges_to_remove_x.append(i)\n",
    "            if not (start_edges[i] in idxs_Y and end_edges[i] in idxs_Y):\n",
    "                edges_to_remove_y.append(i)\n",
    "            if not (start_edges[i] in idxs_XY and end_edges[i] in idxs_XY):\n",
    "                edges_to_remove_xy.append(i)\n",
    "\n",
    "        gx_pruned = graph.clone()\n",
    "        gx_pruned.remove_edges(edges_to_remove_x)\n",
    "        assert gx_pruned.number_of_edges() == gx.number_of_edges() - gx.number_of_nodes() # - because self loop\n",
    "\n",
    "        gx_pruned = gx_pruned.add_self_loop().to(device)\n",
    "\n",
    "        gy_pruned = graph.clone()\n",
    "        gy_pruned.remove_edges(edges_to_remove_y)\n",
    "        assert gy_pruned.number_of_edges() == gy.number_of_edges() - gy.number_of_nodes() # - because self loop\n",
    "\n",
    "        gy_pruned = gy_pruned.add_self_loop().to(device)\n",
    "\n",
    "        gxy_pruned = graph.clone()\n",
    "        gxy_pruned.remove_edges(edges_to_remove_xy)\n",
    "\n",
    "        gxy_pruned = gxy_pruned.add_self_loop().to(device)\n",
    "\n",
    "        x_pruned = torch.zeros(feat.shape)\n",
    "        x_pruned[idxs_X,:] = feat[idxs_X,:]\n",
    "\n",
    "        gcn = GCN(in_dim, hid_dim, out_dim, 2*n_layers, nonlin, build_params_gcn).to(device)\n",
    "        loss_gcn_limited_x, acc_train_gcn_limited_x, acc_val_gcn_limited_x, acc_test_gcn_limited_x, best_acc_test_gcn_limited_x = test(gcn, x_pruned.to(device), labels.to(device), gx, gy, gx_pruned, lr_gcn, train_idx_orig, val_idx_orig, test_idx_orig, model_name=\"gcn\", es_patience=es_patience, verbose=False)\n",
    "\n",
    "        gcn = GCN(in_dim, hid_dim, out_dim, 2*n_layers, nonlin, build_params_gcn).to(device)\n",
    "        loss_gcn_limited_y, acc_train_gcn_limited_y, acc_val_gcn_limited_y, acc_test_gcn_limited_y, best_acc_test_gcn_limited_y = test(gcn, x_pruned.to(device), labels.to(device), gx, gy, gy_pruned, lr_gcn, train_idx_orig, val_idx_orig, test_idx_orig, model_name=\"gcn\", es_patience=es_patience, verbose=False)\n",
    "\n",
    "        gcn = GCN(in_dim, hid_dim, out_dim, 2*n_layers, nonlin, build_params_gcn).to(device)\n",
    "        loss_gcn_limited_xy, acc_train_gcn_limited_xy, acc_val_gcn_limited_xy, acc_test_gcn_limited_xy, best_acc_test_gcn_limited_xy = test(gcn, x_pruned.to(device), labels.to(device), gx, gy, gxy_pruned, lr_gcn, train_idx_orig, val_idx_orig, test_idx_orig, model_name=\"gcn\", es_patience=es_patience, verbose=False)\n",
    "\n",
    "        gat = GAT(in_dim, hid_dim, out_dim, 2*n_layers, nonlin, build_params_gat).to(device)\n",
    "        loss_gat, acc_train_gat, acc_val_gat, acc_test_gat, best_acc_test_gat = test(gat, feat.to(device), labels.to(device), gx, gy, graph.clone().add_self_loop(), lr_gcn, train_idx_orig, val_idx_orig, test_idx_orig, model_name=\"gat\", es_patience=es_patience, verbose=False)\n",
    "\n",
    "        accs_test_gcn[k,sim,:] = acc_test_gcn\n",
    "        best_accs_test_gcn[k,sim] = best_acc_test_gcn\n",
    "        losses_gcn[k,sim,:] = loss_gcn\n",
    "        accs_test_gcn_limited_x[k,sim,:] = acc_test_gcn_limited_x\n",
    "        best_accs_test_gcn_limited_x[k,sim] = best_acc_test_gcn_limited_x\n",
    "        losses_gcn_limited_x[k,sim,:] = loss_gcn_limited_x\n",
    "        accs_test_gcn_limited_y[k,sim,:] = acc_test_gcn_limited_y\n",
    "        best_accs_test_gcn_limited_y[k,sim] = best_acc_test_gcn_limited_y\n",
    "        losses_gcn_limited_y[k,sim,:] = loss_gcn_limited_y\n",
    "        accs_test_gcn_limited_xy[k,sim,:] = acc_test_gcn_limited_xy\n",
    "        best_accs_test_gcn_limited_xy[k,sim] = best_acc_test_gcn_limited_xy\n",
    "        losses_gcn_limited_xy[k,sim,:] = loss_gcn_limited_xy\n",
    "        accs_test_gat[k,sim,:] = acc_test_gat\n",
    "        best_accs_test_gat[k,sim] = best_acc_test_gat\n",
    "        losses_gat[k,sim,:] = loss_gat\n",
    "    \n",
    "    print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science','ieee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "best_acc_test_iogcn, best_acc_test_iogat, best_acc_test_ogcn, best_acc_test_iomlp, best_acc_test_gcn, best_acc_test_gcn_limited_x, best_acc_test_gcn_limited_y, best_acc_test_gcn_limited_xy, best_acc_test_gat = \\\n",
    "    [100*np.mean(elem, 1) for elem in [best_accs_test_iogcn, best_accs_test_iogat, best_accs_test_ogcn, best_accs_test_iomlp, best_accs_test_gcn, best_accs_test_gcn_limited_x, best_accs_test_gcn_limited_y, best_accs_test_gcn_limited_xy, best_accs_test_gat]]\n",
    "\n",
    "plt.plot(Ks[:-1], best_acc_test_iogcn[:-1,0], 'o-', color='b', linewidth=2, label=\"IOGCN-W\")\n",
    "#plt.plot(Ks, best_acc_test_iogat[:,0], 's-', color='r', linewidth=2, label=\"IOGAT-W\")\n",
    "plt.plot(Ks[:-1], best_acc_test_iomlp[:-1,0], 'v-', color='g', linewidth=2, label=\"IOMLP-W\")\n",
    "\n",
    "plt.plot(Ks[:-1], best_acc_test_iogcn[:-1,1], 'o--', color='b', linewidth=2, label=\"IOGCN-T\")\n",
    "#plt.plot(Ks, best_acc_test_iogat[:,1], 's--', color='r', linewidth=2, label=\"IOGAT-T\")\n",
    "#plt.plot(Ks, best_acc_test_iomlp[:,1], 'v--', color='g', linewidth=2, label=\"IOMLP-T\")\n",
    "\n",
    "plt.plot(Ks[:-1], best_acc_test_iogcn[:-1,2], 'o-.', color='b', linewidth=2, label=\"IOGCN-C\")\n",
    "#plt.plot(Ks, best_acc_test_iogat[:,2], 's-.', color='r', linewidth=2, label=\"IOGAT-C\")\n",
    "plt.plot(Ks[:-1], best_acc_test_iomlp[:-1,2], 'v-.', color='g', linewidth=2, label=\"IOMLP-C\")\n",
    "\n",
    "plt.plot(Ks[:-1], best_acc_test_gcn[:-1], 'o-', linewidth=2, color='m', label=\"GCN\")\n",
    "plt.plot(Ks[:-1], best_acc_test_gcn_limited_x[:-1], 'o-', linewidth=2, color='y', label=\"GCN-Limited-$\\mathcal{G}_X$\")\n",
    "plt.plot(Ks[:-1], best_acc_test_gcn_limited_y[:-1], 'o-', linewidth=2, color='orange', label=\"GCN-Limited-$\\mathcal{G}_Y$\")\n",
    "plt.plot(Ks[:-1], best_acc_test_gcn_limited_xy[:-1], 'o-', linewidth=2, color='gray', label=\"GCN-Limited-$\\mathcal{G}_{XY}$\")\n",
    "#plt.plot(Ks, best_acc_test_gat, 'o-', linewidth=2, color='c', label=\"GAT\")\n",
    "\n",
    "plt.xlabel(\"Number of hops for snowball sampling\", fontsize=20)\n",
    "plt.ylabel(\"Mean accuracy over the test node set\", fontsize=20)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "plt.savefig('results/20240111-selection_nodes.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "best_acc_test_iogcn, best_acc_test_iogat, best_acc_test_iomlp, best_acc_test_gcn, best_acc_test_gcn_limited_x, best_acc_test_gcn_limited_y, best_acc_test_gcn_limited_xy, best_acc_test_gat = \\\n",
    "    [100*np.mean(elem, 1) for elem in [best_accs_test_iogcn, best_accs_test_iogat, best_accs_test_ogcn, best_accs_test_iomlp, best_accs_test_gcn, best_accs_test_gcn_limited_x, best_accs_test_gcn_limited_y, best_accs_test_gcn_limited_xy, best_accs_test_gat]]\n",
    "best_acc_test_iogcn_std, best_acc_test_iogat_std, best_acc_test_iomlp_std, best_acc_test_gcn_std, best_acc_test_gcn_limited_x_std, best_acc_test_gcn_limited_y_std, best_acc_test_gcn_limited_xy_std, best_acc_test_gat_std = \\\n",
    "    [100*np.std(elem, 1) for elem in [best_accs_test_iogcn, best_accs_test_iogat, best_accs_test_ogcn, best_accs_test_iomlp, best_accs_test_gcn, best_accs_test_gcn_limited_x, best_accs_test_gcn_limited_y, best_accs_test_gcn_limited_xy, best_accs_test_gat]]\n",
    "\n",
    "plt.errorbar(Ks, best_acc_test_iogcn[:,0], yerr=best_acc_test_iogcn_std[:,0], fmt='o-', color='b', linewidth=3, markersize=12, capsize=5, label=\"IOGCN-W\")\n",
    "#plt.plot(Ks, best_acc_test_iogat[:,0], 's-', color='r', linewidth=2, label=\"IOGAT-W\")\n",
    "plt.errorbar(Ks, best_acc_test_iomlp[:,0], yerr=best_acc_test_iomlp_std[:,0], fmt='v-', color='g', linewidth=3, markersize=12, capsize=5, label=\"IOMLP-W\")\n",
    "\n",
    "plt.errorbar(Ks, best_acc_test_iogcn[:,1], yerr=best_acc_test_iogcn_std[:,1], fmt='o--', color='b', linewidth=3, markersize=12, capsize=5, label=\"IOGCN-T\")\n",
    "#plt.plot(Ks, best_acc_test_iogat[:,1], 's--', color='r', linewidth=2, label=\"IOGAT-T\")\n",
    "#plt.plot(Ks, best_acc_test_iomlp[:,1], 'v--', color='g', linewidth=2, label=\"IOMLP-T\")\n",
    "\n",
    "plt.errorbar(Ks, best_acc_test_iogcn[:,2], yerr=best_acc_test_iogcn_std[:,2], fmt='o-.', color='b', linewidth=3, markersize=12, capsize=5, label=\"IOGCN-C\")\n",
    "#plt.plot(Ks, best_acc_test_iogat[:,2], 's-.', color='r', linewidth=2, label=\"IOGAT-C\")\n",
    "plt.errorbar(Ks, best_acc_test_iomlp[:,2], yerr=best_acc_test_iomlp_std[:,2], fmt='v-.', color='g', linewidth=3, markersize=12, capsize=5, label=\"IOMLP-C\")\n",
    "\n",
    "plt.errorbar(Ks, best_acc_test_gcn, yerr=best_acc_test_gcn_std, fmt='o-', linewidth=3, markersize=12, capsize=5, color='m', label=\"GCN\")\n",
    "plt.errorbar(Ks, best_acc_test_gcn_limited_x, yerr=best_acc_test_gcn_limited_x_std, fmt='o-', linewidth=3, markersize=12, capsize=5, color='y', label=\"GCN-Limited-$\\mathcal{G}_X$\")\n",
    "plt.errorbar(Ks, best_acc_test_gcn_limited_y, yerr=best_acc_test_gcn_limited_y_std, fmt='o-', linewidth=3, markersize=12, capsize=5, color='orange', label=\"GCN-Limited-$\\mathcal{G}_Y$\")\n",
    "plt.errorbar(Ks, best_acc_test_gcn_limited_xy, yerr=best_acc_test_gcn_limited_xy_std, fmt='o-', linewidth=3, markersize=12, capsize=5, color='gray', label=\"GCN-Limited-$\\mathcal{G}_{XY}$\")\n",
    "#plt.plot(Ks, best_acc_test_gat, 'o-', linewidth=2, color='c', label=\"GAT\")\n",
    "\n",
    "plt.xlabel(\"Number of hops for snowball sampling\", fontsize=20)\n",
    "plt.ylabel(\"Mean accuracy over the test node set\", fontsize=20)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "plt.savefig('results/20240111-selection_nodes.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
